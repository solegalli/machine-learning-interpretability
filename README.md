![PythonVersion](https://img.shields.io/badge/python-3.7%20|3.8%20|%203.9%20|%203.10-success)
[![License https://github.com/solegalli/machine-learning-interpretability/blob/master/LICENSE](https://img.shields.io/badge/license-BSD-success.svg)](https://github.com/solegalli/machine-learning-interpretability/blob/master/LICENSE)
[![Sponsorship https://www.trainindata.com/](https://img.shields.io/badge/Powered%20By-TrainInData-orange.svg)](https://www.trainindata.com/)

## Machine Learning Interpretability- Code Repository

Code repository for the online course [Machine Learning Interpretability](https://www.courses.trainindata.com/p/machine-learning-interpretability)

**Coming soon!**

Actively maintained.

[<img src="./mli_logo.png" width="248">](https://www.courses.trainindata.com/p/machine-learning-interpretability)

## Table of Contents

1. **Machine Learning Interpretability**
	1. Interpretability in the context of Machine Learning
	2. Local vs Global Interpretability
	3. Intrinsically explainable models
	4. Post-hoc explainability methods
	5. Challenges to interpretability
	6. How to make models more explainably

2. **Intrinsically Explainable Models**
	1. Linear and Logistic Regression 
	2. Decision trees
	3. Random forests
	4. Gradient boosting machines
	5. Making global and local interpretability

3. **Post-hoc methods - Global explainability**
	1. Permutation Feature Importance
	2. EXPLAIN: hiding features
	3. Partial dependency plots
	4. Other

4. **Post-hoc methods - Local explainability**
	1. LIME
	2. SHAP
	3. Individual contitional expectation
	4. Other


## Links

- [Online Course](https://www.courses.trainindata.com/p/machine-learning-interpretability)
